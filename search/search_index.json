{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"pyRho \u00b6 pyRho is a set of tools for processing volumetric data for material science applications. pyRho is written in Python and supports Python 3.7+. Installation from source \u00b6 You can install pyRho directly from a clone of the Git repository . This can be done either by cloning the repo and installing from the local clone, or simply installing directly via git . shell tab=\"Local Clone\" git clone https://github.com/jmmshn/pyRho cd pyrho python setup.py install","title":"Home"},{"location":"#pyrho","text":"pyRho is a set of tools for processing volumetric data for material science applications. pyRho is written in Python and supports Python 3.7+.","title":"pyRho"},{"location":"#installation-from-source","text":"You can install pyRho directly from a clone of the Git repository . This can be done either by cloning the repo and installing from the local clone, or simply installing directly via git . shell tab=\"Local Clone\" git clone https://github.com/jmmshn/pyRho cd pyrho python setup.py install","title":"Installation from source"},{"location":"CHANGELOG/","text":"Changelog \u00b6 v0.0.21 (2021-04-21) \u00b6 Full Changelog v0.0.20 (2021-03-01) \u00b6 Full Changelog v0.0.19 (2021-03-01) \u00b6 Full Changelog v0.0.18 (2021-03-01) \u00b6 Full Changelog v0.0.16 (2021-03-01) \u00b6 Full Changelog v0.0.17 (2021-03-01) \u00b6 Full Changelog v0.0.15 (2021-02-27) \u00b6 Full Changelog v0.0.14 (2021-02-27) \u00b6 Full Changelog v0.0.13 (2021-02-27) \u00b6 Full Changelog History \u00b6 0.0.0 (2021-02-25) \u00b6 Initial release on PyPI. * This Changelog was automatically generated by github_changelog_generator","title":"Changelog"},{"location":"CHANGELOG/#changelog","text":"","title":"Changelog"},{"location":"CHANGELOG/#v0021-2021-04-21","text":"Full Changelog","title":"v0.0.21 (2021-04-21)"},{"location":"CHANGELOG/#v0020-2021-03-01","text":"Full Changelog","title":"v0.0.20 (2021-03-01)"},{"location":"CHANGELOG/#v0019-2021-03-01","text":"Full Changelog","title":"v0.0.19 (2021-03-01)"},{"location":"CHANGELOG/#v0018-2021-03-01","text":"Full Changelog","title":"v0.0.18 (2021-03-01)"},{"location":"CHANGELOG/#v0016-2021-03-01","text":"Full Changelog","title":"v0.0.16 (2021-03-01)"},{"location":"CHANGELOG/#v0017-2021-03-01","text":"Full Changelog","title":"v0.0.17 (2021-03-01)"},{"location":"CHANGELOG/#v0015-2021-02-27","text":"Full Changelog","title":"v0.0.15 (2021-02-27)"},{"location":"CHANGELOG/#v0014-2021-02-27","text":"Full Changelog","title":"v0.0.14 (2021-02-27)"},{"location":"CHANGELOG/#v0013-2021-02-27","text":"Full Changelog","title":"v0.0.13 (2021-02-27)"},{"location":"CHANGELOG/#history","text":"","title":"History"},{"location":"CHANGELOG/#000-2021-02-25","text":"Initial release on PyPI. * This Changelog was automatically generated by github_changelog_generator","title":"0.0.0 (2021-02-25)"},{"location":"concepts/","text":"Volumetric data in materials science \u00b6 Density Functional Theory (DFT) has been one of the most successfully applied quantum theories with wide range of of applications ranging from in silco materials discovery to simulation of quantum processes. The fundamental tenet of DFT is that all of the energy of a quantum system is completely determined by the charge density alone, which is a much simpler object interms of computational complexity compared with the many-body electronic wave function that is typically needed to describe the system. This make the charge density the central quantity in all of quantum chemistry research. Modern DFT codes can solve for the charge density in finite and periodic systems, allowing to the generation and storage of millions of high-quality charge densities in databases like the Materials Project. Such data sets are often useful for machine learning applications. Since the charge density is scalar field in 3-D \\psi(x,y,z) \\psi(x,y,z) , one would assuming that 3D neural networks can be directly applied to this data. But one major technical challenge remains: representation of the data so that results from different calculations can be directly compared. This is especially problematic for periodic systems where the definition of the periodic lattice vectors determines the basic representation. The data is given as a regular grid in fractional coordinates. In order the compare charge densities from different calculations, we have to represent them all on a Cartesian grid. Storage of volumetric data on a regular grid \u00b6 Interpolation of Periodic data \u00b6 Re-griding \u00b6","title":"Core Concepts"},{"location":"concepts/#volumetric-data-in-materials-science","text":"Density Functional Theory (DFT) has been one of the most successfully applied quantum theories with wide range of of applications ranging from in silco materials discovery to simulation of quantum processes. The fundamental tenet of DFT is that all of the energy of a quantum system is completely determined by the charge density alone, which is a much simpler object interms of computational complexity compared with the many-body electronic wave function that is typically needed to describe the system. This make the charge density the central quantity in all of quantum chemistry research. Modern DFT codes can solve for the charge density in finite and periodic systems, allowing to the generation and storage of millions of high-quality charge densities in databases like the Materials Project. Such data sets are often useful for machine learning applications. Since the charge density is scalar field in 3-D \\psi(x,y,z) \\psi(x,y,z) , one would assuming that 3D neural networks can be directly applied to this data. But one major technical challenge remains: representation of the data so that results from different calculations can be directly compared. This is especially problematic for periodic systems where the definition of the periodic lattice vectors determines the basic representation. The data is given as a regular grid in fractional coordinates. In order the compare charge densities from different calculations, we have to represent them all on a Cartesian grid.","title":"Volumetric data in materials science"},{"location":"concepts/#storage-of-volumetric-data-on-a-regular-grid","text":"","title":"Storage of volumetric data on a regular grid"},{"location":"concepts/#interpolation-of-periodic-data","text":"","title":"Interpolation of Periodic data"},{"location":"concepts/#re-griding","text":"","title":"Re-griding"},{"location":"getting_started/jupyter_setup/","text":"Jupyter notebook setup \u00b6 Basic visualizing is handled through Plotly framework. Data limit \u00b6 Since we are visualizing large grid data, it sometimes pushes the limits of the notebook's default data rate. So we will have to increase the data rate when we call start the notebook. NotebookApp.iopub_data_rate_limit=10000000000 Jupyter-lab integration \u00b6 Plotly dash's Jupyter lab integration is not always stable, but installing it from conda works most of the time. conda install -c conda-forge jupyterlab-plotly-extension","title":"Jupyter Setup"},{"location":"getting_started/jupyter_setup/#jupyter-notebook-setup","text":"Basic visualizing is handled through Plotly framework.","title":"Jupyter notebook setup"},{"location":"getting_started/jupyter_setup/#data-limit","text":"Since we are visualizing large grid data, it sometimes pushes the limits of the notebook's default data rate. So we will have to increase the data rate when we call start the notebook. NotebookApp.iopub_data_rate_limit=10000000000","title":"Data limit"},{"location":"getting_started/jupyter_setup/#jupyter-lab-integration","text":"Plotly dash's Jupyter lab integration is not always stable, but installing it from conda works most of the time. conda install -c conda-forge jupyterlab-plotly-extension","title":"Jupyter-lab integration"},{"location":"reference/core/","text":"Python class for ND grid data volumetric data PGrid \u00b6 __init__ ( self , grid_data , lattice = None ) special \u00b6 Base class for N-dimensional Regular period grid data. The core code should be valid in N-dimensions and not depend on pymatgen Parameters: Name Type Description Default grid_data ndarray Data stored on the regular rid required lattice Optional[numpy.ndarray] list of lattice vectors None Source code in pyrho/core/pgrid.py def __init__ ( self , grid_data : np . ndarray , lattice : Union [ np . ndarray , None ] = None ): \"\"\" Base class for N-dimensional Regular period grid data. The core code should be valid in N-dimensions and not depend on pymatgen Args: grid_data: Data stored on the regular rid lattice: list of lattice vectors \"\"\" if lattice is not None : # type: ignore self . lattice = np . array ( lattice ) self . grid_data = grid_data self . _dim = len ( self . grid_data . shape ) self . grid_shape = self . grid_data . shape self . ngridpts = np . prod ( self . grid_shape ) gaussian_smear ( self , sigma = 0.2 , arr_in = None ) \u00b6 Applies an isotropic Gaussian smear of width (standard deviation) r to the potential field. This is necessary to avoid finding paths through narrow minima or nodes that may exist in the field (although any potential or charge distribution generated from GGA should be relatively smooth anyway). The smearing obeys periodic boundary conditions at the edges of the cell. Parameters: Name Type Description Default sigma float Smearing width in cartesian coordinates, in the same units as the 0.2 arr_in ndarray input data array to smear, if None: smear self.grid_data None Source code in pyrho/core/pgrid.py def gaussian_smear ( self , sigma : float = 0.2 , arr_in : np . ndarray = None ) -> Tuple [ np . ndarray , np . ndarray ]: \"\"\" Applies an isotropic Gaussian smear of width (standard deviation) r to the potential field. This is necessary to avoid finding paths through narrow minima or nodes that may exist in the field (although any potential or charge distribution generated from GGA should be relatively smooth anyway). The smearing obeys periodic boundary conditions at the edges of the cell. Args: sigma: Smearing width in cartesian coordinates, in the same units as the structure lattice vectors arr_in: input data array to smear, if None: smear self.grid_data \"\"\" # get the dimension of the filter needed for 1 std dev of gaussian mask # Go 4 standard deviations away if arr_in is None : arr = self . grid_data else : arr = arr_in r_frac = get_ucell_frac_fit_sphere ( lattice = self . lattice , r = sigma * 5 ) filter_shape = [ int ( np . ceil ( itr_rf * itr_dim / 2 ) * 2 ) # dimension of the filter should be even for itr_rf , itr_dim in zip ( r_frac , arr . shape ) ] filter_latt = np . array ([( filter_shape [ _ ] + 1 ) / ( arr . shape [ _ ] + 1 ) * self . lattice [ _ ] for _ in range ( self . _dim )]) # Get the fractional positions filter_frac_c = [ np . linspace ( 0 , 1 , _ , endpoint = False ) for _ in filter_shape ] frac_pos = np . meshgrid ( * filter_frac_c , indexing = \"ij\" ) frac_pos = [ _ . flatten () for _ in frac_pos ] # convert to cartesian cart_pos = np . matmul ( filter_latt . T , np . vstack ( frac_pos )) # Distance the center if 1d we make this iterable tmp = sum ( filter_latt ) # type: Union[float, np.ndarray] if isinstance ( tmp , np . ndarray ): mid_point = tmp / 2 # type: Union[List, np.ndarray] else : mid_point = [ tmp / 2 ] disp2mid2 = [( i_coord . reshape ( filter_shape ) - mp_coord ) ** 2 for mp_coord , i_coord in zip ( mid_point , cart_pos )] dist2mid = np . sqrt ( sum ( disp2mid2 )) # make sure the mask is zero? mm = dist2mid <= sigma * 4 gauss = np . exp ( - 1 / 2 * ( dist2mid / sigma ) ** 2 ) * mm gauss = gauss / gauss . sum () return convolve ( input = arr , weights = gauss , mode = \"wrap\" ), gauss get_transformed_data ( self , sc_mat , frac_shift , grid_out , up_sample = 1 ) \u00b6 Apply a transformation to the grid data This function assumes that the data is fixed in place and the transformation is applied to the lattice vectors. Parameters: Name Type Description Default sc_mat Union[int, float, complex, str, bytes, numpy.generic, Sequence[Union[int, float, complex, str, bytes, numpy.generic]], Sequence[Sequence[Any]], numpy._array_like._SupportsArray] matrix transformation applied to the lattice vectors required frac_shift Union[int, float, complex, str, bytes, numpy.generic, Sequence[Union[int, float, complex, str, bytes, numpy.generic]], Sequence[Sequence[Any]], numpy._array_like._SupportsArray] shift the lattice in fractional coordinates of the input cell required up_sample int the factor to scale up the sampling of the grid data 1 sc_mat ---> [2, 1] trans ---> [0.1, 0.3] [0, 1] new lattice vectors: a = [0.2, 0.4] --> [2.2, 1.4] b = [0.2, 0.4] --> [0.2, 1.1] Returns: Type Description ndarray transformed data Source code in pyrho/core/pgrid.py def get_transformed_data ( self , sc_mat : npt . ArrayLike , frac_shift : npt . ArrayLike , grid_out : List [ int ], up_sample : int = 1 , ) -> np . ndarray : \"\"\" Apply a transformation to the grid data This function assumes that the data is fixed in place and the transformation is applied to the lattice vectors. Args: sc_mat: matrix transformation applied to the lattice vectors frac_shift: shift the lattice in fractional coordinates of the input cell up_sample: the factor to scale up the sampling of the grid data sc_mat ---> [2, 1] trans ---> [0.1, 0.3] [0, 1] new lattice vectors: a = [0.2, 0.4] --> [2.2, 1.4] b = [0.2, 0.4] --> [0.2, 1.1] Returns: transformed data \"\"\" if up_sample == 1 : interp_grid_data = self . grid_data else : interp_grid_data = interpolate_fourier ( arr_in = self . grid_data , shape = [ g_dim_ * up_sample for g_dim_ in self . grid_data . shape ], ) _ , new_rho = get_sc_interp ( interp_grid_data , sc_mat , grid_sizes = grid_out , origin = frac_shift ) # type: ignore new_rho = new_rho . reshape ( grid_out ) # TODO make this part of the original transformation # grid_shifts = [ # int(t * g) for t, g in zip(frac_shift - np.round(frac_shift), grid_out) # ] # # new_rho = roll_array(new_rho, grid_shifts) return new_rho get_transformed_obj ( self , sc_mat , frac_shift , grid_out , up_sample = 1 ) \u00b6 Get a new PGrid object for the new transformed data Parameters: Name Type Description Default sc_mat Union[List[List[int]], numpy.ndarray] matrix transformation applied to the lattice vectors required frac_shift Union[numpy.ndarray, List[float], Tuple[float]] shift the lattice in fractional coordinates of the output cell required grid_out List[int] The size of the output grid to interpolate on required up_sample int the factor to scale up the sampling of the grid data 1 Returns: Type Description PGrid New PGrid object Source code in pyrho/core/pgrid.py def get_transformed_obj ( self , sc_mat : Union [ List [ List [ int ]], np . ndarray ], frac_shift : Union [ np . ndarray , List [ float ], Tuple [ float ]], grid_out : List [ int ], up_sample : int = 1 , ) -> \"PGrid\" : \"\"\" Get a new PGrid object for the new transformed data Args: sc_mat: matrix transformation applied to the lattice vectors frac_shift: shift the lattice in fractional coordinates of the output cell grid_out: The size of the output grid to interpolate on up_sample: the factor to scale up the sampling of the grid data Returns: New PGrid object \"\"\" new_data = self . get_transformed_data ( sc_mat , frac_shift , grid_out = grid_out , up_sample = up_sample ) new_lattice = np . dot ( sc_mat , self . lattice ) return PGrid ( grid_data = new_data , lattice = new_lattice ) lossy_smooth_compression ( self , grid_out , smear_std = 0.2 ) \u00b6 Perform Fourier interpolation then Gaussian smoothing. the smoothing makes sure that simple operation like max and min filters still give the same results. Parameters: Name Type Description Default grid_out List desired output grid of the compressed data, required Returns: Type Description ndarray Smoothed array Source code in pyrho/core/pgrid.py def lossy_smooth_compression ( self , grid_out : List , smear_std : float = 0.2 ) -> np . ndarray : \"\"\" Perform Fourier interpolation then Gaussian smoothing. the smoothing makes sure that simple operation like max and min filters still give the same results. Args: grid_out: desired output grid of the compressed data, Returns: Smoothed array \"\"\" arr_interp = np . absolute ( interpolate_fourier ( self . grid_data , grid_out )) if smear_std > 0 : arr_interp , _ = self . gaussian_smear ( arr_in = arr_interp , sigma = smear_std ) return arr_interp Fourier analysis functions. PFourier \u00b6 cartesian_reciprocal_pos : ndarray property readonly \u00b6 Get the list of reciprocal lattice points in cartesian coordinates fft_pos_centered : ndarray property readonly \u00b6 Return the fft positions where the N-k is changed to -k fft_pos_centered_cartesian : List property readonly \u00b6 Return the fft positions where the N-k is changed to -k fft_pos_centered_cartesian_s : List property readonly \u00b6 Return the fft positions where the N-k is changed to -k fft_pos_centered_s : ndarray property readonly \u00b6 Return the fft positions where the N-k is changed to -k fractional_reciprocal_pos : ndarray property readonly \u00b6 Return fft position structured grid Assuming standard fft format A[N-1] = A[-1] reciprocal_lattice : ndarray property readonly \u00b6 Return the reciprocal lattice. Note that this is the standard reciprocal lattice used for solid state physics with a factor of 2 * pi. __init__ ( self , fourier_data , lattice ) special \u00b6 Fourier transform defined for a periodic function. The representation must be SC agnostic, (i.e. if we double the size of the unit cell) Much of the analysis relies on the fact that numpy.ndarray.flatten puts the array in a particular order. The correct ordering is used but not strictly enforced by the present code so use with care. Also make sure the fourier data is generated in the correct way: with index='ij' Parameters: Name Type Description Default fourier_data ndarray Complex data for each point in fourier_pos required lattice Union[int, float, complex, str, bytes, numpy.generic, Sequence[Union[int, float, complex, str, bytes, numpy.generic]], Sequence[Sequence[Any]], numpy._array_like._SupportsArray] The corresponding real space lattice parameters required Source code in pyrho/core/fourier.py def __init__ ( self , fourier_data : np . ndarray , lattice : npt . ArrayLike ): \"\"\" Fourier transform defined for a periodic function. The representation must be SC agnostic, (i.e. if we double the size of the unit cell) Much of the analysis relies on the fact that numpy.ndarray.flatten puts the array in a particular order. The correct ordering is used but not strictly enforced by the present code so use with care. Also make sure the fourier data is generated in the correct way: with index='ij' Args: fourier_data: Complex data for each point in fourier_pos lattice: The corresponding real space lattice parameters \"\"\" self . lattice = np . array ( lattice ) self . fourier_data = fourier_data self . shape = fourier_data . shape get_points_dict ( self , filter_pos = None , filter_val = None ) \u00b6 Return filtered data as a (position, fft_coefficient) pair Parameters: Name Type Description Default filter_val Callable Filter function applied to the fourier data values (Example: Only keep large Fourier weights) None ftiler_pos Filter function applied to the reciprocal positions (Example: low pass filter) required Source code in pyrho/core/fourier.py def get_points_dict ( self , filter_pos : Callable = None , filter_val : Callable = None ): \"\"\" Return filtered data as a (position, fft_coefficient) pair Args: filter_val: Filter function applied to the fourier data values (Example: Only keep large Fourier weights) ftiler_pos: Filter function applied to the reciprocal positions (Example: low pass filter) \"\"\" for cart_pos , val in zip ( self . cartesian_reciprocal_pos . T , self . fourier_data . flatten ()): if filter_val is not None and not filter_val ( val ): continue if filter_pos is not None and not filter_pos ( cart_pos ): continue yield cart_pos , val Chang Density Objects: Periodic Grid + Lattice / Atoms ChargeDensity \u00b6 lattice : ndarray property readonly \u00b6 Override the lattice definition in PGrid, this makes getting the reoriented charge density easier. rho : ndarray property readonly \u00b6 Alias for the grid data, which should be the true charge density __init__ ( self , grid_data , structure , normalization = 'vasp' ) special \u00b6 Class that contains functions to featurize volumetic data with periodic boundary conditions. Make sure the data being stored is grid-independent Parameters: Name Type Description Default grid_data ndarray Volumetric data to read in required structure Structure Atomic structure corresponding to the charge density required normalization str the normalization scheme: - 'vasp' sum of the data / number of grid points == number of electrons 'vasp' Source code in pyrho/core/chargeDensity.py def __init__ ( self , grid_data : np . ndarray , structure : Structure , normalization : str = \"vasp\" , ): \"\"\" Class that contains functions to featurize volumetic data with periodic boundary conditions. Make sure the data being stored is grid-independent Args: grid_data: Volumetric data to read in structure: Atomic structure corresponding to the charge density normalization: the normalization scheme: - 'vasp' sum of the data / number of grid points == number of electrons \"\"\" self . structure = structure . copy () self . normalization = normalization if normalization [ 0 ] . lower () == \"n\" : \"\"\" No rescaling \"\"\" scaled_data = grid_data elif normalization [ 0 ] . lower () == \"v\" : \"\"\" the standard charge density from VASP is given as (rho*V) such that: sum(rho)/NGRID = NELECT/UC_vol so the real rho is: rho = (rho*UC_vol)*NGRID/UC_vol/UC_vol where the second V account for the different number of electrons in different cells \"\"\" scaled_data = grid_data / self . structure . volume else : raise NotImplementedError ( \"Not a valid normalization scheme\" ) super () . __init__ ( grid_data = scaled_data , lattice = None ) from_pmg_volumetric_data ( vdata , data_key = 'total' ) classmethod \u00b6 Read a single key from the data field of a VolumetricData object Parameters: Name Type Description Default vdata VolumetricData The volumetric data object required data_key The key to read from in the data field 'total' Returns: Type Description ChargeDensity ChargeDensity object Source code in pyrho/core/chargeDensity.py @classmethod def from_pmg_volumetric_data ( cls , vdata : VolumetricData , data_key = \"total\" ) -> \"ChargeDensity\" : \"\"\" Read a single key from the data field of a VolumetricData object Args: vdata: The volumetric data object data_key: The key to read from in the data field Returns: ChargeDensity object \"\"\" return cls ( grid_data = vdata . data [ data_key ], structure = vdata . structure , normalization = \"vasp\" , ) get_transformed_obj ( self , sc_mat = (( 1 , 0 , 0 ), ( 0 , 1 , 0 ), ( 0 , 0 , 1 )), frac_shift = ( 0.0 , 0.0 , 0.0 ), grid_out = 1000000000 , up_sample = 1 ) \u00b6 Modify the structure and data and return a new object containing the reshaped data Parameters: Name Type Description Default sc_mat Union[int, float, complex, str, bytes, numpy.generic, Sequence[Union[int, float, complex, str, bytes, numpy.generic]], Sequence[Sequence[Any]], numpy._array_like._SupportsArray] Matrix to create the new cell ((1, 0, 0), (0, 1, 0), (0, 0, 1)) frac_shift Union[int, float, complex, str, bytes, numpy.generic, Sequence[Union[int, float, complex, str, bytes, numpy.generic]], Sequence[Sequence[Any]], numpy._array_like._SupportsArray] translation to be applied on the cell after the matrix (0.0, 0.0, 0.0) grid_out Union[List[int], int] density of the new grid, can also just take the desired 1000000000 Returns: Type Description ChargeDensity Source code in pyrho/core/chargeDensity.py def get_transformed_obj ( self , sc_mat : npt . ArrayLike = (( 1 , 0 , 0 ), ( 0 , 1 , 0 ), ( 0 , 0 , 1 )), frac_shift : npt . ArrayLike = ( 0.0 , 0.0 , 0.0 ), grid_out : Union [ List [ int ], int ] = int ( 1e9 ), up_sample : int = 1 , ) -> \"ChargeDensity\" : \"\"\" Modify the structure and data and return a new object containing the reshaped data Args: sc_mat: Matrix to create the new cell frac_shift: translation to be applied on the cell after the matrix transformation grid_out: density of the new grid, can also just take the desired dimension as a list. Returns: \"\"\" new_structure = self . structure . copy () new_structure . translate_sites ( list ( range ( len ( new_structure ))), - np . array ( frac_shift ) ) new_structure = new_structure * sc_mat # determine the output grid lengths = new_structure . lattice . abc if isinstance ( grid_out , int ): ngrid = grid_out / new_structure . volume mult = ( np . prod ( lengths ) / ngrid ) ** ( 1 / 3 ) grid_out = [ int ( math . floor ( max ( l_ / mult , 1 ))) for l_ in lengths ] else : grid_out = grid_out new_rho = self . get_transformed_data ( sc_mat , frac_shift , grid_out = grid_out , up_sample = up_sample ) return ChargeDensity . from_rho ( new_rho , new_structure , self . normalization ) reorient_axis ( self ) \u00b6 Change the orientation of the lattice vector so that: a points along the x-axis, b is in the xy-plane, c is in the positive-z halve of space Source code in pyrho/core/chargeDensity.py def reorient_axis ( self ) -> None : \"\"\" Change the orientation of the lattice vector so that: a points along the x-axis, b is in the xy-plane, c is in the positive-z halve of space \"\"\" args = ( self . structure . lattice . abc + self . structure . lattice . angles ) # type: Tuple[float, float, float, float, float, float] self . structure . lattice = Lattice . from_parameters ( * args , vesta = True ) SpinChargeDensity \u00b6 __init__ ( self , chargeden_dict , aug_charge = None ) special \u00b6 Wrapper class that parses multiple sets of grid data on the same lattice Parameters: Name Type Description Default chargeden_dict Dict A dictionary containing multiple charge density objects typically in the format {'total' : ChargeDen1, 'diff' : ChargeDen2} required Source code in pyrho/core/chargeDensity.py def __init__ ( self , chargeden_dict : Dict , aug_charge : Dict = None ): \"\"\" Wrapper class that parses multiple sets of grid data on the same lattice Args: chargeden_dict: A dictionary containing multiple charge density objects typically in the format {'total' : ChargeDen1, 'diff' : ChargeDen2} \"\"\" self . chargeden_dict = chargeden_dict self . aug_charge = aug_charge self . _tmp_key = next ( iter ( self . chargeden_dict ) ) # get one key in the dictionary to make writing the subsequent code easier multiply_aug ( data_aug , factor ) \u00b6 The original idea here was to use to to speed up some vasp calculations for supercells by initializing the entire CHGCAR file. The current code does not deal with transformation of the Augemetation charges after regridding. This is a naive way to multiply the Augmentation data in the CHGCAR, a real working implementation will require analysis of the PAW projection operators. However, even with such an implementation, the speed up will be minimal due to VASP's interal minimization algorithms. Parameters: Name Type Description Default data_aug List[str] The original augmentation data from a CHGCAR required factor int The multiplication factor (some integer number of times it gets repeated) required Returns: Type Description List[str] List of strings for each line of the Augmentation data. Source code in pyrho/core/chargeDensity.py def multiply_aug ( data_aug : List [ str ], factor : int ) -> List [ str ]: \"\"\" The original idea here was to use to to speed up some vasp calculations for supercells by initializing the entire CHGCAR file. The current code does not deal with transformation of the Augemetation charges after regridding. This is a naive way to multiply the Augmentation data in the CHGCAR, a real working implementation will require analysis of the PAW projection operators. However, even with such an implementation, the speed up will be minimal due to VASP's interal minimization algorithms. Args: data_aug: The original augmentation data from a CHGCAR factor: The multiplication factor (some integer number of times it gets repeated) Returns: List of strings for each line of the Augmentation data. \"\"\" res = [] # type: List[str] cur_block = [] # type: List[str] cnt = 0 for ll in data_aug : if \"augmentation\" in ll : if cur_block : for j in range ( factor ): cnt += 1 cur_block [ 0 ] = f \"augmentation occupancies { cnt : >4 }{ cur_block [ 0 ] . split ()[ - 1 ] : >4 } \\n \" res . extend ( cur_block ) cur_block = [ ll ] else : cur_block . append ( ll ) else : for j in range ( factor ): cnt += 1 cur_block [ 0 ] = f \"augmentation occupancies { cnt : >4 }{ cur_block [ 0 ] . split ()[ - 1 ] : >4 } \\n \" res . extend ( cur_block ) return res","title":"core"},{"location":"reference/core/#pyrho.core.pgrid.PGrid","text":"","title":"PGrid"},{"location":"reference/core/#pyrho.core.pgrid.PGrid.__init__","text":"Base class for N-dimensional Regular period grid data. The core code should be valid in N-dimensions and not depend on pymatgen Parameters: Name Type Description Default grid_data ndarray Data stored on the regular rid required lattice Optional[numpy.ndarray] list of lattice vectors None Source code in pyrho/core/pgrid.py def __init__ ( self , grid_data : np . ndarray , lattice : Union [ np . ndarray , None ] = None ): \"\"\" Base class for N-dimensional Regular period grid data. The core code should be valid in N-dimensions and not depend on pymatgen Args: grid_data: Data stored on the regular rid lattice: list of lattice vectors \"\"\" if lattice is not None : # type: ignore self . lattice = np . array ( lattice ) self . grid_data = grid_data self . _dim = len ( self . grid_data . shape ) self . grid_shape = self . grid_data . shape self . ngridpts = np . prod ( self . grid_shape )","title":"__init__()"},{"location":"reference/core/#pyrho.core.pgrid.PGrid.gaussian_smear","text":"Applies an isotropic Gaussian smear of width (standard deviation) r to the potential field. This is necessary to avoid finding paths through narrow minima or nodes that may exist in the field (although any potential or charge distribution generated from GGA should be relatively smooth anyway). The smearing obeys periodic boundary conditions at the edges of the cell. Parameters: Name Type Description Default sigma float Smearing width in cartesian coordinates, in the same units as the 0.2 arr_in ndarray input data array to smear, if None: smear self.grid_data None Source code in pyrho/core/pgrid.py def gaussian_smear ( self , sigma : float = 0.2 , arr_in : np . ndarray = None ) -> Tuple [ np . ndarray , np . ndarray ]: \"\"\" Applies an isotropic Gaussian smear of width (standard deviation) r to the potential field. This is necessary to avoid finding paths through narrow minima or nodes that may exist in the field (although any potential or charge distribution generated from GGA should be relatively smooth anyway). The smearing obeys periodic boundary conditions at the edges of the cell. Args: sigma: Smearing width in cartesian coordinates, in the same units as the structure lattice vectors arr_in: input data array to smear, if None: smear self.grid_data \"\"\" # get the dimension of the filter needed for 1 std dev of gaussian mask # Go 4 standard deviations away if arr_in is None : arr = self . grid_data else : arr = arr_in r_frac = get_ucell_frac_fit_sphere ( lattice = self . lattice , r = sigma * 5 ) filter_shape = [ int ( np . ceil ( itr_rf * itr_dim / 2 ) * 2 ) # dimension of the filter should be even for itr_rf , itr_dim in zip ( r_frac , arr . shape ) ] filter_latt = np . array ([( filter_shape [ _ ] + 1 ) / ( arr . shape [ _ ] + 1 ) * self . lattice [ _ ] for _ in range ( self . _dim )]) # Get the fractional positions filter_frac_c = [ np . linspace ( 0 , 1 , _ , endpoint = False ) for _ in filter_shape ] frac_pos = np . meshgrid ( * filter_frac_c , indexing = \"ij\" ) frac_pos = [ _ . flatten () for _ in frac_pos ] # convert to cartesian cart_pos = np . matmul ( filter_latt . T , np . vstack ( frac_pos )) # Distance the center if 1d we make this iterable tmp = sum ( filter_latt ) # type: Union[float, np.ndarray] if isinstance ( tmp , np . ndarray ): mid_point = tmp / 2 # type: Union[List, np.ndarray] else : mid_point = [ tmp / 2 ] disp2mid2 = [( i_coord . reshape ( filter_shape ) - mp_coord ) ** 2 for mp_coord , i_coord in zip ( mid_point , cart_pos )] dist2mid = np . sqrt ( sum ( disp2mid2 )) # make sure the mask is zero? mm = dist2mid <= sigma * 4 gauss = np . exp ( - 1 / 2 * ( dist2mid / sigma ) ** 2 ) * mm gauss = gauss / gauss . sum () return convolve ( input = arr , weights = gauss , mode = \"wrap\" ), gauss","title":"gaussian_smear()"},{"location":"reference/core/#pyrho.core.pgrid.PGrid.get_transformed_data","text":"Apply a transformation to the grid data This function assumes that the data is fixed in place and the transformation is applied to the lattice vectors. Parameters: Name Type Description Default sc_mat Union[int, float, complex, str, bytes, numpy.generic, Sequence[Union[int, float, complex, str, bytes, numpy.generic]], Sequence[Sequence[Any]], numpy._array_like._SupportsArray] matrix transformation applied to the lattice vectors required frac_shift Union[int, float, complex, str, bytes, numpy.generic, Sequence[Union[int, float, complex, str, bytes, numpy.generic]], Sequence[Sequence[Any]], numpy._array_like._SupportsArray] shift the lattice in fractional coordinates of the input cell required up_sample int the factor to scale up the sampling of the grid data 1 sc_mat ---> [2, 1] trans ---> [0.1, 0.3] [0, 1] new lattice vectors: a = [0.2, 0.4] --> [2.2, 1.4] b = [0.2, 0.4] --> [0.2, 1.1] Returns: Type Description ndarray transformed data Source code in pyrho/core/pgrid.py def get_transformed_data ( self , sc_mat : npt . ArrayLike , frac_shift : npt . ArrayLike , grid_out : List [ int ], up_sample : int = 1 , ) -> np . ndarray : \"\"\" Apply a transformation to the grid data This function assumes that the data is fixed in place and the transformation is applied to the lattice vectors. Args: sc_mat: matrix transformation applied to the lattice vectors frac_shift: shift the lattice in fractional coordinates of the input cell up_sample: the factor to scale up the sampling of the grid data sc_mat ---> [2, 1] trans ---> [0.1, 0.3] [0, 1] new lattice vectors: a = [0.2, 0.4] --> [2.2, 1.4] b = [0.2, 0.4] --> [0.2, 1.1] Returns: transformed data \"\"\" if up_sample == 1 : interp_grid_data = self . grid_data else : interp_grid_data = interpolate_fourier ( arr_in = self . grid_data , shape = [ g_dim_ * up_sample for g_dim_ in self . grid_data . shape ], ) _ , new_rho = get_sc_interp ( interp_grid_data , sc_mat , grid_sizes = grid_out , origin = frac_shift ) # type: ignore new_rho = new_rho . reshape ( grid_out ) # TODO make this part of the original transformation # grid_shifts = [ # int(t * g) for t, g in zip(frac_shift - np.round(frac_shift), grid_out) # ] # # new_rho = roll_array(new_rho, grid_shifts) return new_rho","title":"get_transformed_data()"},{"location":"reference/core/#pyrho.core.pgrid.PGrid.get_transformed_obj","text":"Get a new PGrid object for the new transformed data Parameters: Name Type Description Default sc_mat Union[List[List[int]], numpy.ndarray] matrix transformation applied to the lattice vectors required frac_shift Union[numpy.ndarray, List[float], Tuple[float]] shift the lattice in fractional coordinates of the output cell required grid_out List[int] The size of the output grid to interpolate on required up_sample int the factor to scale up the sampling of the grid data 1 Returns: Type Description PGrid New PGrid object Source code in pyrho/core/pgrid.py def get_transformed_obj ( self , sc_mat : Union [ List [ List [ int ]], np . ndarray ], frac_shift : Union [ np . ndarray , List [ float ], Tuple [ float ]], grid_out : List [ int ], up_sample : int = 1 , ) -> \"PGrid\" : \"\"\" Get a new PGrid object for the new transformed data Args: sc_mat: matrix transformation applied to the lattice vectors frac_shift: shift the lattice in fractional coordinates of the output cell grid_out: The size of the output grid to interpolate on up_sample: the factor to scale up the sampling of the grid data Returns: New PGrid object \"\"\" new_data = self . get_transformed_data ( sc_mat , frac_shift , grid_out = grid_out , up_sample = up_sample ) new_lattice = np . dot ( sc_mat , self . lattice ) return PGrid ( grid_data = new_data , lattice = new_lattice )","title":"get_transformed_obj()"},{"location":"reference/core/#pyrho.core.pgrid.PGrid.lossy_smooth_compression","text":"Perform Fourier interpolation then Gaussian smoothing. the smoothing makes sure that simple operation like max and min filters still give the same results. Parameters: Name Type Description Default grid_out List desired output grid of the compressed data, required Returns: Type Description ndarray Smoothed array Source code in pyrho/core/pgrid.py def lossy_smooth_compression ( self , grid_out : List , smear_std : float = 0.2 ) -> np . ndarray : \"\"\" Perform Fourier interpolation then Gaussian smoothing. the smoothing makes sure that simple operation like max and min filters still give the same results. Args: grid_out: desired output grid of the compressed data, Returns: Smoothed array \"\"\" arr_interp = np . absolute ( interpolate_fourier ( self . grid_data , grid_out )) if smear_std > 0 : arr_interp , _ = self . gaussian_smear ( arr_in = arr_interp , sigma = smear_std ) return arr_interp Fourier analysis functions.","title":"lossy_smooth_compression()"},{"location":"reference/core/#pyrho.core.fourier.PFourier","text":"","title":"PFourier"},{"location":"reference/core/#pyrho.core.fourier.PFourier.cartesian_reciprocal_pos","text":"Get the list of reciprocal lattice points in cartesian coordinates","title":"cartesian_reciprocal_pos"},{"location":"reference/core/#pyrho.core.fourier.PFourier.fft_pos_centered","text":"Return the fft positions where the N-k is changed to -k","title":"fft_pos_centered"},{"location":"reference/core/#pyrho.core.fourier.PFourier.fft_pos_centered_cartesian","text":"Return the fft positions where the N-k is changed to -k","title":"fft_pos_centered_cartesian"},{"location":"reference/core/#pyrho.core.fourier.PFourier.fft_pos_centered_cartesian_s","text":"Return the fft positions where the N-k is changed to -k","title":"fft_pos_centered_cartesian_s"},{"location":"reference/core/#pyrho.core.fourier.PFourier.fft_pos_centered_s","text":"Return the fft positions where the N-k is changed to -k","title":"fft_pos_centered_s"},{"location":"reference/core/#pyrho.core.fourier.PFourier.fractional_reciprocal_pos","text":"Return fft position structured grid Assuming standard fft format A[N-1] = A[-1]","title":"fractional_reciprocal_pos"},{"location":"reference/core/#pyrho.core.fourier.PFourier.reciprocal_lattice","text":"Return the reciprocal lattice. Note that this is the standard reciprocal lattice used for solid state physics with a factor of 2 * pi.","title":"reciprocal_lattice"},{"location":"reference/core/#pyrho.core.fourier.PFourier.__init__","text":"Fourier transform defined for a periodic function. The representation must be SC agnostic, (i.e. if we double the size of the unit cell) Much of the analysis relies on the fact that numpy.ndarray.flatten puts the array in a particular order. The correct ordering is used but not strictly enforced by the present code so use with care. Also make sure the fourier data is generated in the correct way: with index='ij' Parameters: Name Type Description Default fourier_data ndarray Complex data for each point in fourier_pos required lattice Union[int, float, complex, str, bytes, numpy.generic, Sequence[Union[int, float, complex, str, bytes, numpy.generic]], Sequence[Sequence[Any]], numpy._array_like._SupportsArray] The corresponding real space lattice parameters required Source code in pyrho/core/fourier.py def __init__ ( self , fourier_data : np . ndarray , lattice : npt . ArrayLike ): \"\"\" Fourier transform defined for a periodic function. The representation must be SC agnostic, (i.e. if we double the size of the unit cell) Much of the analysis relies on the fact that numpy.ndarray.flatten puts the array in a particular order. The correct ordering is used but not strictly enforced by the present code so use with care. Also make sure the fourier data is generated in the correct way: with index='ij' Args: fourier_data: Complex data for each point in fourier_pos lattice: The corresponding real space lattice parameters \"\"\" self . lattice = np . array ( lattice ) self . fourier_data = fourier_data self . shape = fourier_data . shape","title":"__init__()"},{"location":"reference/core/#pyrho.core.fourier.PFourier.get_points_dict","text":"Return filtered data as a (position, fft_coefficient) pair Parameters: Name Type Description Default filter_val Callable Filter function applied to the fourier data values (Example: Only keep large Fourier weights) None ftiler_pos Filter function applied to the reciprocal positions (Example: low pass filter) required Source code in pyrho/core/fourier.py def get_points_dict ( self , filter_pos : Callable = None , filter_val : Callable = None ): \"\"\" Return filtered data as a (position, fft_coefficient) pair Args: filter_val: Filter function applied to the fourier data values (Example: Only keep large Fourier weights) ftiler_pos: Filter function applied to the reciprocal positions (Example: low pass filter) \"\"\" for cart_pos , val in zip ( self . cartesian_reciprocal_pos . T , self . fourier_data . flatten ()): if filter_val is not None and not filter_val ( val ): continue if filter_pos is not None and not filter_pos ( cart_pos ): continue yield cart_pos , val Chang Density Objects: Periodic Grid + Lattice / Atoms","title":"get_points_dict()"},{"location":"reference/core/#pyrho.core.chargeDensity.ChargeDensity","text":"","title":"ChargeDensity"},{"location":"reference/core/#pyrho.core.chargeDensity.ChargeDensity.lattice","text":"Override the lattice definition in PGrid, this makes getting the reoriented charge density easier.","title":"lattice"},{"location":"reference/core/#pyrho.core.chargeDensity.ChargeDensity.rho","text":"Alias for the grid data, which should be the true charge density","title":"rho"},{"location":"reference/core/#pyrho.core.chargeDensity.ChargeDensity.__init__","text":"Class that contains functions to featurize volumetic data with periodic boundary conditions. Make sure the data being stored is grid-independent Parameters: Name Type Description Default grid_data ndarray Volumetric data to read in required structure Structure Atomic structure corresponding to the charge density required normalization str the normalization scheme: - 'vasp' sum of the data / number of grid points == number of electrons 'vasp' Source code in pyrho/core/chargeDensity.py def __init__ ( self , grid_data : np . ndarray , structure : Structure , normalization : str = \"vasp\" , ): \"\"\" Class that contains functions to featurize volumetic data with periodic boundary conditions. Make sure the data being stored is grid-independent Args: grid_data: Volumetric data to read in structure: Atomic structure corresponding to the charge density normalization: the normalization scheme: - 'vasp' sum of the data / number of grid points == number of electrons \"\"\" self . structure = structure . copy () self . normalization = normalization if normalization [ 0 ] . lower () == \"n\" : \"\"\" No rescaling \"\"\" scaled_data = grid_data elif normalization [ 0 ] . lower () == \"v\" : \"\"\" the standard charge density from VASP is given as (rho*V) such that: sum(rho)/NGRID = NELECT/UC_vol so the real rho is: rho = (rho*UC_vol)*NGRID/UC_vol/UC_vol where the second V account for the different number of electrons in different cells \"\"\" scaled_data = grid_data / self . structure . volume else : raise NotImplementedError ( \"Not a valid normalization scheme\" ) super () . __init__ ( grid_data = scaled_data , lattice = None )","title":"__init__()"},{"location":"reference/core/#pyrho.core.chargeDensity.ChargeDensity.from_pmg_volumetric_data","text":"Read a single key from the data field of a VolumetricData object Parameters: Name Type Description Default vdata VolumetricData The volumetric data object required data_key The key to read from in the data field 'total' Returns: Type Description ChargeDensity ChargeDensity object Source code in pyrho/core/chargeDensity.py @classmethod def from_pmg_volumetric_data ( cls , vdata : VolumetricData , data_key = \"total\" ) -> \"ChargeDensity\" : \"\"\" Read a single key from the data field of a VolumetricData object Args: vdata: The volumetric data object data_key: The key to read from in the data field Returns: ChargeDensity object \"\"\" return cls ( grid_data = vdata . data [ data_key ], structure = vdata . structure , normalization = \"vasp\" , )","title":"from_pmg_volumetric_data()"},{"location":"reference/core/#pyrho.core.chargeDensity.ChargeDensity.get_transformed_obj","text":"Modify the structure and data and return a new object containing the reshaped data Parameters: Name Type Description Default sc_mat Union[int, float, complex, str, bytes, numpy.generic, Sequence[Union[int, float, complex, str, bytes, numpy.generic]], Sequence[Sequence[Any]], numpy._array_like._SupportsArray] Matrix to create the new cell ((1, 0, 0), (0, 1, 0), (0, 0, 1)) frac_shift Union[int, float, complex, str, bytes, numpy.generic, Sequence[Union[int, float, complex, str, bytes, numpy.generic]], Sequence[Sequence[Any]], numpy._array_like._SupportsArray] translation to be applied on the cell after the matrix (0.0, 0.0, 0.0) grid_out Union[List[int], int] density of the new grid, can also just take the desired 1000000000 Returns: Type Description ChargeDensity Source code in pyrho/core/chargeDensity.py def get_transformed_obj ( self , sc_mat : npt . ArrayLike = (( 1 , 0 , 0 ), ( 0 , 1 , 0 ), ( 0 , 0 , 1 )), frac_shift : npt . ArrayLike = ( 0.0 , 0.0 , 0.0 ), grid_out : Union [ List [ int ], int ] = int ( 1e9 ), up_sample : int = 1 , ) -> \"ChargeDensity\" : \"\"\" Modify the structure and data and return a new object containing the reshaped data Args: sc_mat: Matrix to create the new cell frac_shift: translation to be applied on the cell after the matrix transformation grid_out: density of the new grid, can also just take the desired dimension as a list. Returns: \"\"\" new_structure = self . structure . copy () new_structure . translate_sites ( list ( range ( len ( new_structure ))), - np . array ( frac_shift ) ) new_structure = new_structure * sc_mat # determine the output grid lengths = new_structure . lattice . abc if isinstance ( grid_out , int ): ngrid = grid_out / new_structure . volume mult = ( np . prod ( lengths ) / ngrid ) ** ( 1 / 3 ) grid_out = [ int ( math . floor ( max ( l_ / mult , 1 ))) for l_ in lengths ] else : grid_out = grid_out new_rho = self . get_transformed_data ( sc_mat , frac_shift , grid_out = grid_out , up_sample = up_sample ) return ChargeDensity . from_rho ( new_rho , new_structure , self . normalization )","title":"get_transformed_obj()"},{"location":"reference/core/#pyrho.core.chargeDensity.ChargeDensity.reorient_axis","text":"Change the orientation of the lattice vector so that: a points along the x-axis, b is in the xy-plane, c is in the positive-z halve of space Source code in pyrho/core/chargeDensity.py def reorient_axis ( self ) -> None : \"\"\" Change the orientation of the lattice vector so that: a points along the x-axis, b is in the xy-plane, c is in the positive-z halve of space \"\"\" args = ( self . structure . lattice . abc + self . structure . lattice . angles ) # type: Tuple[float, float, float, float, float, float] self . structure . lattice = Lattice . from_parameters ( * args , vesta = True )","title":"reorient_axis()"},{"location":"reference/core/#pyrho.core.chargeDensity.SpinChargeDensity","text":"","title":"SpinChargeDensity"},{"location":"reference/core/#pyrho.core.chargeDensity.SpinChargeDensity.__init__","text":"Wrapper class that parses multiple sets of grid data on the same lattice Parameters: Name Type Description Default chargeden_dict Dict A dictionary containing multiple charge density objects typically in the format {'total' : ChargeDen1, 'diff' : ChargeDen2} required Source code in pyrho/core/chargeDensity.py def __init__ ( self , chargeden_dict : Dict , aug_charge : Dict = None ): \"\"\" Wrapper class that parses multiple sets of grid data on the same lattice Args: chargeden_dict: A dictionary containing multiple charge density objects typically in the format {'total' : ChargeDen1, 'diff' : ChargeDen2} \"\"\" self . chargeden_dict = chargeden_dict self . aug_charge = aug_charge self . _tmp_key = next ( iter ( self . chargeden_dict ) ) # get one key in the dictionary to make writing the subsequent code easier","title":"__init__()"},{"location":"reference/core/#pyrho.core.chargeDensity.multiply_aug","text":"The original idea here was to use to to speed up some vasp calculations for supercells by initializing the entire CHGCAR file. The current code does not deal with transformation of the Augemetation charges after regridding. This is a naive way to multiply the Augmentation data in the CHGCAR, a real working implementation will require analysis of the PAW projection operators. However, even with such an implementation, the speed up will be minimal due to VASP's interal minimization algorithms. Parameters: Name Type Description Default data_aug List[str] The original augmentation data from a CHGCAR required factor int The multiplication factor (some integer number of times it gets repeated) required Returns: Type Description List[str] List of strings for each line of the Augmentation data. Source code in pyrho/core/chargeDensity.py def multiply_aug ( data_aug : List [ str ], factor : int ) -> List [ str ]: \"\"\" The original idea here was to use to to speed up some vasp calculations for supercells by initializing the entire CHGCAR file. The current code does not deal with transformation of the Augemetation charges after regridding. This is a naive way to multiply the Augmentation data in the CHGCAR, a real working implementation will require analysis of the PAW projection operators. However, even with such an implementation, the speed up will be minimal due to VASP's interal minimization algorithms. Args: data_aug: The original augmentation data from a CHGCAR factor: The multiplication factor (some integer number of times it gets repeated) Returns: List of strings for each line of the Augmentation data. \"\"\" res = [] # type: List[str] cur_block = [] # type: List[str] cnt = 0 for ll in data_aug : if \"augmentation\" in ll : if cur_block : for j in range ( factor ): cnt += 1 cur_block [ 0 ] = f \"augmentation occupancies { cnt : >4 }{ cur_block [ 0 ] . split ()[ - 1 ] : >4 } \\n \" res . extend ( cur_block ) cur_block = [ ll ] else : cur_block . append ( ll ) else : for j in range ( factor ): cnt += 1 cur_block [ 0 ] = f \"augmentation occupancies { cnt : >4 }{ cur_block [ 0 ] . split ()[ - 1 ] : >4 } \\n \" res . extend ( cur_block ) return res","title":"multiply_aug()"},{"location":"reference/vis/","text":"Helper functions to visualize the data in plotly get_plotly_scatter_plot ( data_in , lat_mat , skips = 5 , logcolor = False , mask = None , opacity = 0.5 , marker_size = 5 ) \u00b6 Returns a plotly fig object for plotting. Parameters: Name Type Description Default data_in ndarray Structured grid data to be plotted required lat_mat ndarray Lattice vectors of the cell required skips int reduction factor of the grid points for plotting, only show [::skips] in each direction 5 logcolor bool If True, assign the color in log scale False mask ndarray Filter the points to plot None opacity float opacity of each point being plotted 0.5 marker_size int size of the markers in the 3D scatter plot 5 Returns: Type Description Figure plotly Figure object Source code in pyrho/vis/plotly.py def get_plotly_scatter_plot ( data_in : np . ndarray , lat_mat : np . ndarray , skips : int = 5 , logcolor : bool = False , mask : np . ndarray = None , opacity : float = 0.5 , marker_size : int = 5 , ) -> go . Figure : \"\"\" Returns a plotly fig object for plotting. Args: data_in: Structured grid data to be plotted lat_mat: Lattice vectors of the cell skips: reduction factor of the grid points for plotting, only show [::skips] in each direction logcolor: If True, assign the color in log scale mask: Filter the points to plot opacity: opacity of each point being plotted marker_size: size of the markers in the 3D scatter plot Returns: plotly Figure object \"\"\" ndim = len ( data_in . shape ) if ndim > 3 : raise NotImplementedError ( \"Can only render data of 1, 2, or 3 dimensions.\" ) ss = slice ( 0 , None , skips ) trimmed_data = np . real ( data_in ) . copy () trimmed_data = trimmed_data [( ss ,) * ndim ] if mask is not None : flat_mask = mask [( ss ,) * ndim ] . flatten () else : flat_mask = np . ones_like ( trimmed_data , dtype = bool ) . flatten () vecs = [ np . linspace ( 0 , 1 , trimmed_data . shape [ _ ], endpoint = False ) for _ in range ( ndim )] gridded = np . meshgrid ( * vecs , indexing = \"ij\" ) # indexing to match the labeled array res = np . dot ( lat_mat . T , [ g_ . flatten () for g_ in gridded ]) if logcolor : cc = np . log ( trimmed_data . flatten ()) else : cc = trimmed_data . flatten () if ndim == 1 : xx = res [ flat_mask ] elif ndim > 1 : xx = res [ 0 , flat_mask ] yy = res [ 1 , flat_mask ] if ndim > 2 : zz = res [ 2 , flat_mask ] cc = cc [ flat_mask ] if ndim == 1 : data = go . Scatter ( x = xx , y = cc , mode = \"markers\" , marker = dict ( size = marker_size , color = \"red\" ,)) if ndim == 2 : data = go . Scatter ( x = xx , y = yy , mode = \"markers\" , marker = dict ( size = marker_size , color = cc , # set color to an array/list of desired values colorscale = \"Viridis\" , # choose a colorscale opacity = opacity , ), ) if ndim == 3 : data = go . Scatter3d ( x = xx , y = yy , z = zz , mode = \"markers\" , marker = dict ( size = marker_size , color = cc , colorscale = \"Viridis\" , opacity = opacity ,), ) fig = go . Figure ( data = [ data ]) fig . update_layout ( template = \"plotly_white\" ) if ndim == 2 : fig . update_layout ( width = 800 , height = 800 , yaxis = dict ( scaleanchor = \"x\" , scaleratio = 1 )) if ndim == 3 : fig . update_layout ( width = 800 , height = 800 , scene_aspectmode = \"data\" ) return fig","title":"vis"},{"location":"reference/vis/#pyrho.vis.plotly.get_plotly_scatter_plot","text":"Returns a plotly fig object for plotting. Parameters: Name Type Description Default data_in ndarray Structured grid data to be plotted required lat_mat ndarray Lattice vectors of the cell required skips int reduction factor of the grid points for plotting, only show [::skips] in each direction 5 logcolor bool If True, assign the color in log scale False mask ndarray Filter the points to plot None opacity float opacity of each point being plotted 0.5 marker_size int size of the markers in the 3D scatter plot 5 Returns: Type Description Figure plotly Figure object Source code in pyrho/vis/plotly.py def get_plotly_scatter_plot ( data_in : np . ndarray , lat_mat : np . ndarray , skips : int = 5 , logcolor : bool = False , mask : np . ndarray = None , opacity : float = 0.5 , marker_size : int = 5 , ) -> go . Figure : \"\"\" Returns a plotly fig object for plotting. Args: data_in: Structured grid data to be plotted lat_mat: Lattice vectors of the cell skips: reduction factor of the grid points for plotting, only show [::skips] in each direction logcolor: If True, assign the color in log scale mask: Filter the points to plot opacity: opacity of each point being plotted marker_size: size of the markers in the 3D scatter plot Returns: plotly Figure object \"\"\" ndim = len ( data_in . shape ) if ndim > 3 : raise NotImplementedError ( \"Can only render data of 1, 2, or 3 dimensions.\" ) ss = slice ( 0 , None , skips ) trimmed_data = np . real ( data_in ) . copy () trimmed_data = trimmed_data [( ss ,) * ndim ] if mask is not None : flat_mask = mask [( ss ,) * ndim ] . flatten () else : flat_mask = np . ones_like ( trimmed_data , dtype = bool ) . flatten () vecs = [ np . linspace ( 0 , 1 , trimmed_data . shape [ _ ], endpoint = False ) for _ in range ( ndim )] gridded = np . meshgrid ( * vecs , indexing = \"ij\" ) # indexing to match the labeled array res = np . dot ( lat_mat . T , [ g_ . flatten () for g_ in gridded ]) if logcolor : cc = np . log ( trimmed_data . flatten ()) else : cc = trimmed_data . flatten () if ndim == 1 : xx = res [ flat_mask ] elif ndim > 1 : xx = res [ 0 , flat_mask ] yy = res [ 1 , flat_mask ] if ndim > 2 : zz = res [ 2 , flat_mask ] cc = cc [ flat_mask ] if ndim == 1 : data = go . Scatter ( x = xx , y = cc , mode = \"markers\" , marker = dict ( size = marker_size , color = \"red\" ,)) if ndim == 2 : data = go . Scatter ( x = xx , y = yy , mode = \"markers\" , marker = dict ( size = marker_size , color = cc , # set color to an array/list of desired values colorscale = \"Viridis\" , # choose a colorscale opacity = opacity , ), ) if ndim == 3 : data = go . Scatter3d ( x = xx , y = yy , z = zz , mode = \"markers\" , marker = dict ( size = marker_size , color = cc , colorscale = \"Viridis\" , opacity = opacity ,), ) fig = go . Figure ( data = [ data ]) fig . update_layout ( template = \"plotly_white\" ) if ndim == 2 : fig . update_layout ( width = 800 , height = 800 , yaxis = dict ( scaleanchor = \"x\" , scaleratio = 1 )) if ndim == 3 : fig . update_layout ( width = 800 , height = 800 , scene_aspectmode = \"data\" ) return fig","title":"get_plotly_scatter_plot()"}]}