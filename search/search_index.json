{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"pyRho \u00b6 pyRho is a set of tools for processing volumetric data for material science applications. pyRho is written in Python and supports Python 3.7+. Installation from source \u00b6 You can install pyRho directly from a clone of the Git repository . This can be done either by cloning the repo and installing from the local clone, or simply installing directly via git . Local Clone git clone https://github.com/jmmshn/pyRho cd pyrho python setup.py install","title":"Home"},{"location":"#pyrho","text":"pyRho is a set of tools for processing volumetric data for material science applications. pyRho is written in Python and supports Python 3.7+.","title":"pyRho"},{"location":"#installation-from-source","text":"You can install pyRho directly from a clone of the Git repository . This can be done either by cloning the repo and installing from the local clone, or simply installing directly via git . Local Clone git clone https://github.com/jmmshn/pyRho cd pyrho python setup.py install","title":"Installation from source"},{"location":"concepts/","text":"Volumetric data in materials science \u00b6 Density Functional Theory (DFT) has been one of the most successfully applied quantum theories with wide range of of applications ranging from in silco materials discovery to simulation of quantum processes. The fundamental tenet of DFT is that all of the energy of a quantum system is completely determined by the charge density alone, which is a much simpler object interms of computational complexity compared with the many-body electronic wave function that is typically needed to describe the system. This make the charge density the central quantity in all of quantum chemistry research. Modern DFT codes can solve for the charge density in finite and periodic systems, allowing to the generation and storage of millions of high-quality charge densities in databases like the Materials Project. Such data sets are often useful for machine learning applications. Since the charge density is scalar field in 3-D \\psi(x,y,z) \\psi(x,y,z) , one would assuming that 3D neural networks can be directly applied to this data. But one major technical challenge remains: representation of the data so that results from different calculations can be directly compared. This is especially problematic for periodic systems where the definition of the periodic lattice vectors determines the basic representation. The data is given as a regular grid in fractional coordinates. In order the compare charge densities from different calculations, we have to represent them all on a Cartesian grid. Storage of volumetric data on a regular grid \u00b6 Interpolation of Periodic data \u00b6 Re-griding \u00b6","title":"Core Concepts"},{"location":"concepts/#volumetric-data-in-materials-science","text":"Density Functional Theory (DFT) has been one of the most successfully applied quantum theories with wide range of of applications ranging from in silco materials discovery to simulation of quantum processes. The fundamental tenet of DFT is that all of the energy of a quantum system is completely determined by the charge density alone, which is a much simpler object interms of computational complexity compared with the many-body electronic wave function that is typically needed to describe the system. This make the charge density the central quantity in all of quantum chemistry research. Modern DFT codes can solve for the charge density in finite and periodic systems, allowing to the generation and storage of millions of high-quality charge densities in databases like the Materials Project. Such data sets are often useful for machine learning applications. Since the charge density is scalar field in 3-D \\psi(x,y,z) \\psi(x,y,z) , one would assuming that 3D neural networks can be directly applied to this data. But one major technical challenge remains: representation of the data so that results from different calculations can be directly compared. This is especially problematic for periodic systems where the definition of the periodic lattice vectors determines the basic representation. The data is given as a regular grid in fractional coordinates. In order the compare charge densities from different calculations, we have to represent them all on a Cartesian grid.","title":"Volumetric data in materials science"},{"location":"concepts/#storage-of-volumetric-data-on-a-regular-grid","text":"","title":"Storage of volumetric data on a regular grid"},{"location":"concepts/#interpolation-of-periodic-data","text":"","title":"Interpolation of Periodic data"},{"location":"concepts/#re-griding","text":"","title":"Re-griding"},{"location":"getting_started/jupyter_setup/","text":"Jupyter notebook setup \u00b6 Basic visualizing is handled through Plotly framework. Data limit \u00b6 Since we are visualizing large grid data, it sometimes pushes the limits of the notebook's default data rate. So we will have to increase the data rate when we call start the notebook. NotebookApp.iopub_data_rate_limit=10000000000 Jupyter-lab integration \u00b6 Plotly dash's Jupyter lab integration is not always stable, but installing it from conda works most of the time. conda install -c conda-forge jupyterlab-plotly-extension","title":"Jupyter Setup"},{"location":"getting_started/jupyter_setup/#jupyter-notebook-setup","text":"Basic visualizing is handled through Plotly framework.","title":"Jupyter notebook setup"},{"location":"getting_started/jupyter_setup/#data-limit","text":"Since we are visualizing large grid data, it sometimes pushes the limits of the notebook's default data rate. So we will have to increase the data rate when we call start the notebook. NotebookApp.iopub_data_rate_limit=10000000000","title":"Data limit"},{"location":"getting_started/jupyter_setup/#jupyter-lab-integration","text":"Plotly dash's Jupyter lab integration is not always stable, but installing it from conda works most of the time. conda install -c conda-forge jupyterlab-plotly-extension","title":"Jupyter-lab integration"},{"location":"reference/core/","text":"\u00b6 Python class for ND grid data volumetric data PGrid \u00b6 __init__ ( self , grid_data , lattice = None ) special \u00b6 Base class for N-dimensional Regular period grid data. The core code should be valid in N-dimensions and not depend on pymatgen Parameters: Name Type Description Default grid_data ndarray Data stored on the regular rid required lattice Union[numpy.ndarray, List[List[float]]] list of lattice vectors None Source code in pyrho/core/pgrid.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def __init__ ( self , grid_data : np . ndarray , lattice : Union [ np . ndarray , List [ List [ float ]]] = None ): \"\"\" Base class for N-dimensional Regular period grid data. The core code should be valid in N-dimensions and not depend on pymatgen Args: grid_data: Data stored on the regular rid lattice: list of lattice vectors \"\"\" if lattice is not None : # Some children will set the lattice self . lattice = np . array ( lattice ) self . grid_data = grid_data self . _dim = len ( self . grid_data . shape ) self . grid_shape = self . grid_data . shape self . ngridpts = np . prod ( self . grid_shape ) gaussian_smear ( self , sigma = 0.2 , arr_in = None ) \u00b6 Applies an isotropic Gaussian smear of width (standard deviation) r to the potential field. This is necessary to avoid finding paths through narrow minima or nodes that may exist in the field (although any potential or charge distribution generated from GGA should be relatively smooth anyway). The smearing obeys periodic boundary conditions at the edges of the cell. Parameters: Name Type Description Default sigma float Smearing width in cartesian coordinates, in the same units as the 0.2 arr_in ndarray input data array to smear, if None: smear self.grid_data None Source code in pyrho/core/pgrid.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 def gaussian_smear ( self , sigma : float = 0.2 , arr_in : np . ndarray = None ) -> np . ndarray : \"\"\" Applies an isotropic Gaussian smear of width (standard deviation) r to the potential field. This is necessary to avoid finding paths through narrow minima or nodes that may exist in the field (although any potential or charge distribution generated from GGA should be relatively smooth anyway). The smearing obeys periodic boundary conditions at the edges of the cell. Args: sigma: Smearing width in cartesian coordinates, in the same units as the structure lattice vectors arr_in: input data array to smear, if None: smear self.grid_data \"\"\" # get the dimension of the filter needed for 1 std dev of gaussian mask # Go 4 standard deviations away if arr_in is None : arr = self . grid_data else : arr = arr_in r_frac = get_ucell_frac_fit_sphere ( lattice = self . lattice , r = sigma * 5 ) filter_shape = [ int ( np . ceil ( itr_rf * itr_dim / 2 ) * 2 ) # dimension of the filter should be even for itr_rf , itr_dim in zip ( r_frac , arr . shape ) ] filter_latt = np . array ( [ ( filter_shape [ _ ] + 1 ) / ( arr . shape [ _ ] + 1 ) * self . lattice [ _ ] for _ in range ( self . _dim ) ] ) # Get the fractional positions filter_frac_c = [ np . linspace ( 0 , 1 , _ , endpoint = False ) for _ in filter_shape ] frac_pos = np . meshgrid ( * filter_frac_c , indexing = \"ij\" ) frac_pos = [ _ . flatten () for _ in frac_pos ] # convert to cartesian cart_pos = np . matmul ( filter_latt . T , np . vstack ( frac_pos )) # Distance the center if 1d we make this iterable tmp = sum ( filter_latt ) # type: Union[float, np.ndarray[float]] if isinstance ( tmp , np . ndarray ): mid_point = tmp / 2 # type: Union[List, np.ndarray] else : mid_point = [ tmp / 2 ] disp2mid2 = [ ( i_coord . reshape ( filter_shape ) - mp_coord ) ** 2 for mp_coord , i_coord in zip ( mid_point , cart_pos ) ] dist2mid = np . sqrt ( sum ( disp2mid2 )) # make sure the mask is zero? mm = dist2mid <= sigma * 4 gauss = np . exp ( - 1 / 2 * ( dist2mid / sigma ) ** 2 ) * mm gauss = gauss / gauss . sum () return convolve ( input = arr , weights = gauss , mode = \"wrap\" ), gauss get_transformed_data ( self , sc_mat , frac_shift , grid_out ) \u00b6 Apply a transformation to the grid data This function assumes that the data is fixed in place and the transformation is applied to the lattice vectors. Parameters: Name Type Description Default sc_mat ndarray matrix transformation applied to the lattice vectors required frac_shift ndarray shift the lattice in fractional coordinates of the output cell required sc_mat ---> [2, 1] trans ---> [0.1, 0.3] [0, 1] new lattice vectors: a = [0.2, 0.4] --> [2.2, 1.4] b = [0.2, 0.4] --> [0.2, 1.1] Returns: Type Description ndarray transformed data Source code in pyrho/core/pgrid.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def get_transformed_data ( self , sc_mat : np . ndarray , frac_shift : np . ndarray , grid_out : List [ int ] ) -> np . ndarray : \"\"\" Apply a transformation to the grid data This function assumes that the data is fixed in place and the transformation is applied to the lattice vectors. Args: sc_mat: matrix transformation applied to the lattice vectors frac_shift: shift the lattice in fractional coordinates of the output cell sc_mat ---> [2, 1] trans ---> [0.1, 0.3] [0, 1] new lattice vectors: a = [0.2, 0.4] --> [2.2, 1.4] b = [0.2, 0.4] --> [0.2, 1.1] Returns: transformed data \"\"\" _ , new_rho = get_sc_interp ( self . grid_data , sc_mat , grid_sizes = grid_out ) new_rho = new_rho . reshape ( grid_out ) grid_shifts = [ int ( t * g ) for t , g in zip ( frac_shift - np . round ( frac_shift ), grid_out ) ] new_rho = roll_array ( new_rho , grid_shifts ) return new_rho get_transformed_obj ( self , sc_mat , frac_shift , grid_out ) \u00b6 Get a new PGrid object for the new transformed data Parameters: Name Type Description Default sc_mat ndarray matrix transformation applied to the lattice vectors required frac_shift List[float] shift the lattice in fractional coordinates of the output cell required Returns: Type Description PGrid New PGrid object Source code in pyrho/core/pgrid.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def get_transformed_obj ( self , sc_mat : np . ndarray , frac_shift : List [ float ], grid_out : List [ int ] ) -> \"PGrid\" : \"\"\" Get a new PGrid object for the new transformed data Args: sc_mat: matrix transformation applied to the lattice vectors frac_shift: shift the lattice in fractional coordinates of the output cell Returns: New PGrid object \"\"\" new_data = self . get_transformed_data ( sc_mat , frac_shift , grid_out = grid_out ) new_lattice = np . matmul ( sc_mat , np . array ( self . lattice ) . T ) return PGrid ( grid_data = new_data , lattice = new_lattice ) lossy_smooth_compression ( self , grid_out , smear_std = 0.2 ) \u00b6 Perform Fourier interpolation then Gaussian smoothing. the smoothing makes sure that simple operation like max and min filters still give the same results. Parameters: Name Type Description Default grid_out List desired output grid of the compressed data, required Returns: Type Description ndarray Smoothed array Source code in pyrho/core/pgrid.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 def lossy_smooth_compression ( self , grid_out : List , smear_std : float = 0.2 ) -> np . ndarray : \"\"\" Perform Fourier interpolation then Gaussian smoothing. the smoothing makes sure that simple operation like max and min filters still give the same results. Args: grid_out: desired output grid of the compressed data, Returns: Smoothed array \"\"\" arr_interp = np . absolute ( interpolate_fourier ( self . grid_data , grid_out )) if smear_std > 0 : arr_interp , _ = self . gaussian_smear ( arr_in = arr_interp , sigma = smear_std ) return arr_interp \u00b6 Main module. ChargeDensity \u00b6 lattice: Lattice property readonly \u00b6 Override the lattice definition in PGrid rho: ndarray property readonly \u00b6 Alias for the grid data, which should be the true charge density __init__ ( self , grid_data , structure , normalization = 'vasp' ) special \u00b6 Class that contains functions to featurize volumetic data with periodic boundary conditions. Make sure the data being stored is grid-independent Parameters: Name Type Description Default grid_data ndarray Volumetric data to read in required structure Structure Atomic structure corresponding to the charge density required normalization str the normalization scheme: - 'vasp' sum of the data / number of grid points == number of electrons 'vasp' Source code in pyrho/core/chargeDensity.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def __init__ ( self , grid_data : np . ndarray , structure : Structure , normalization : str = \"vasp\" , ): \"\"\" Class that contains functions to featurize volumetic data with periodic boundary conditions. Make sure the data being stored is grid-independent Args: grid_data: Volumetric data to read in structure: Atomic structure corresponding to the charge density normalization: the normalization scheme: - 'vasp' sum of the data / number of grid points == number of electrons \"\"\" self . structure = structure . copy () self . normalization = normalization if normalization [ 0 ] . lower () == \"n\" : \"\"\" No rescaling \"\"\" scaled_data = grid_data elif normalization [ 0 ] . lower () == \"v\" : \"\"\" the standard charge density from VASP is given as (rho*V) such that: sum(rho)/NGRID = NELECT/UC_vol so the real rho is: rho = (rho*UC_vol)*NGRID/UC_vol/UC_vol where the second V account for the different number of electrons in different cells \"\"\" scaled_data = grid_data / self . structure . volume else : raise NotImplementedError ( \"Not a valid normalization scheme\" ) super () . __init__ ( grid_data = scaled_data , lattice = None ) get_reshaped_cell ( self , sc_mat , frac_shift , new_grid = 1000000000 ) \u00b6 Motify the structure and data and return a new object containing the reshaped data Parameters: Name Type Description Default sc_mat Matrix to create the new cell required frac_shift translation to be applied on the cell after the matrix required new_grid density of the new grid, can also just take the desired 1000000000 Source code in pyrho/core/chargeDensity.py 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 def get_reshaped_cell ( self , sc_mat , frac_shift , new_grid = int ( 1e9 )): \"\"\" Motify the structure and data and return a new object containing the reshaped data Args: sc_mat: Matrix to create the new cell frac_shift: translation to be applied on the cell after the matrix transformation new_grid: density of the new grid, can also just take the desired dimension as a list. Returns: \"\"\" new_structure = self . structure * sc_mat new_structure . translate_sites ( list ( range ( len ( new_structure ))), - np . array ( frac_shift ) ) # determine the output grid lengths = new_structure . lattice . abc if isinstance ( new_grid , int ): ngrid = new_grid / new_structure . volume mult = ( np . prod ( lengths ) / ngrid ) ** ( 1 / 3 ) grid_out = [ int ( math . floor ( max ( l / mult , 1 ))) for l in lengths ] else : grid_out = new_grid new_rho = self . get_transformed_data ( sc_mat , frac_shift , grid_out = grid_out ) return self . from_rho ( new_rho , new_structure , self . normalization ) reorient_axis ( self ) \u00b6 Change the orgientation of the lattice vector so that: a points along the x-axis, b is in the xy-plane, c is in the positive-z halve of space Source code in pyrho/core/chargeDensity.py 102 103 104 105 106 107 108 109 def reorient_axis ( self ) -> None : \"\"\" Change the orgientation of the lattice vector so that: a points along the x-axis, b is in the xy-plane, c is in the positive-z halve of space \"\"\" self . structure . lattice = Lattice . from_parameters ( * self . structure . lattice . abc , * self . structure . lattice . angles , vesta = True )","title":"core"},{"location":"reference/core/#pyrho.core.pgrid","text":"Python class for ND grid data volumetric data","title":"pyrho.core.pgrid"},{"location":"reference/core/#pyrho.core.pgrid.PGrid","text":"","title":"PGrid"},{"location":"reference/core/#pyrho.core.pgrid.PGrid.__init__","text":"Base class for N-dimensional Regular period grid data. The core code should be valid in N-dimensions and not depend on pymatgen Parameters: Name Type Description Default grid_data ndarray Data stored on the regular rid required lattice Union[numpy.ndarray, List[List[float]]] list of lattice vectors None Source code in pyrho/core/pgrid.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def __init__ ( self , grid_data : np . ndarray , lattice : Union [ np . ndarray , List [ List [ float ]]] = None ): \"\"\" Base class for N-dimensional Regular period grid data. The core code should be valid in N-dimensions and not depend on pymatgen Args: grid_data: Data stored on the regular rid lattice: list of lattice vectors \"\"\" if lattice is not None : # Some children will set the lattice self . lattice = np . array ( lattice ) self . grid_data = grid_data self . _dim = len ( self . grid_data . shape ) self . grid_shape = self . grid_data . shape self . ngridpts = np . prod ( self . grid_shape )","title":"__init__()"},{"location":"reference/core/#pyrho.core.pgrid.PGrid.gaussian_smear","text":"Applies an isotropic Gaussian smear of width (standard deviation) r to the potential field. This is necessary to avoid finding paths through narrow minima or nodes that may exist in the field (although any potential or charge distribution generated from GGA should be relatively smooth anyway). The smearing obeys periodic boundary conditions at the edges of the cell. Parameters: Name Type Description Default sigma float Smearing width in cartesian coordinates, in the same units as the 0.2 arr_in ndarray input data array to smear, if None: smear self.grid_data None Source code in pyrho/core/pgrid.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 def gaussian_smear ( self , sigma : float = 0.2 , arr_in : np . ndarray = None ) -> np . ndarray : \"\"\" Applies an isotropic Gaussian smear of width (standard deviation) r to the potential field. This is necessary to avoid finding paths through narrow minima or nodes that may exist in the field (although any potential or charge distribution generated from GGA should be relatively smooth anyway). The smearing obeys periodic boundary conditions at the edges of the cell. Args: sigma: Smearing width in cartesian coordinates, in the same units as the structure lattice vectors arr_in: input data array to smear, if None: smear self.grid_data \"\"\" # get the dimension of the filter needed for 1 std dev of gaussian mask # Go 4 standard deviations away if arr_in is None : arr = self . grid_data else : arr = arr_in r_frac = get_ucell_frac_fit_sphere ( lattice = self . lattice , r = sigma * 5 ) filter_shape = [ int ( np . ceil ( itr_rf * itr_dim / 2 ) * 2 ) # dimension of the filter should be even for itr_rf , itr_dim in zip ( r_frac , arr . shape ) ] filter_latt = np . array ( [ ( filter_shape [ _ ] + 1 ) / ( arr . shape [ _ ] + 1 ) * self . lattice [ _ ] for _ in range ( self . _dim ) ] ) # Get the fractional positions filter_frac_c = [ np . linspace ( 0 , 1 , _ , endpoint = False ) for _ in filter_shape ] frac_pos = np . meshgrid ( * filter_frac_c , indexing = \"ij\" ) frac_pos = [ _ . flatten () for _ in frac_pos ] # convert to cartesian cart_pos = np . matmul ( filter_latt . T , np . vstack ( frac_pos )) # Distance the center if 1d we make this iterable tmp = sum ( filter_latt ) # type: Union[float, np.ndarray[float]] if isinstance ( tmp , np . ndarray ): mid_point = tmp / 2 # type: Union[List, np.ndarray] else : mid_point = [ tmp / 2 ] disp2mid2 = [ ( i_coord . reshape ( filter_shape ) - mp_coord ) ** 2 for mp_coord , i_coord in zip ( mid_point , cart_pos ) ] dist2mid = np . sqrt ( sum ( disp2mid2 )) # make sure the mask is zero? mm = dist2mid <= sigma * 4 gauss = np . exp ( - 1 / 2 * ( dist2mid / sigma ) ** 2 ) * mm gauss = gauss / gauss . sum () return convolve ( input = arr , weights = gauss , mode = \"wrap\" ), gauss","title":"gaussian_smear()"},{"location":"reference/core/#pyrho.core.pgrid.PGrid.get_transformed_data","text":"Apply a transformation to the grid data This function assumes that the data is fixed in place and the transformation is applied to the lattice vectors. Parameters: Name Type Description Default sc_mat ndarray matrix transformation applied to the lattice vectors required frac_shift ndarray shift the lattice in fractional coordinates of the output cell required sc_mat ---> [2, 1] trans ---> [0.1, 0.3] [0, 1] new lattice vectors: a = [0.2, 0.4] --> [2.2, 1.4] b = [0.2, 0.4] --> [0.2, 1.1] Returns: Type Description ndarray transformed data Source code in pyrho/core/pgrid.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def get_transformed_data ( self , sc_mat : np . ndarray , frac_shift : np . ndarray , grid_out : List [ int ] ) -> np . ndarray : \"\"\" Apply a transformation to the grid data This function assumes that the data is fixed in place and the transformation is applied to the lattice vectors. Args: sc_mat: matrix transformation applied to the lattice vectors frac_shift: shift the lattice in fractional coordinates of the output cell sc_mat ---> [2, 1] trans ---> [0.1, 0.3] [0, 1] new lattice vectors: a = [0.2, 0.4] --> [2.2, 1.4] b = [0.2, 0.4] --> [0.2, 1.1] Returns: transformed data \"\"\" _ , new_rho = get_sc_interp ( self . grid_data , sc_mat , grid_sizes = grid_out ) new_rho = new_rho . reshape ( grid_out ) grid_shifts = [ int ( t * g ) for t , g in zip ( frac_shift - np . round ( frac_shift ), grid_out ) ] new_rho = roll_array ( new_rho , grid_shifts ) return new_rho","title":"get_transformed_data()"},{"location":"reference/core/#pyrho.core.pgrid.PGrid.get_transformed_obj","text":"Get a new PGrid object for the new transformed data Parameters: Name Type Description Default sc_mat ndarray matrix transformation applied to the lattice vectors required frac_shift List[float] shift the lattice in fractional coordinates of the output cell required Returns: Type Description PGrid New PGrid object Source code in pyrho/core/pgrid.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def get_transformed_obj ( self , sc_mat : np . ndarray , frac_shift : List [ float ], grid_out : List [ int ] ) -> \"PGrid\" : \"\"\" Get a new PGrid object for the new transformed data Args: sc_mat: matrix transformation applied to the lattice vectors frac_shift: shift the lattice in fractional coordinates of the output cell Returns: New PGrid object \"\"\" new_data = self . get_transformed_data ( sc_mat , frac_shift , grid_out = grid_out ) new_lattice = np . matmul ( sc_mat , np . array ( self . lattice ) . T ) return PGrid ( grid_data = new_data , lattice = new_lattice )","title":"get_transformed_obj()"},{"location":"reference/core/#pyrho.core.pgrid.PGrid.lossy_smooth_compression","text":"Perform Fourier interpolation then Gaussian smoothing. the smoothing makes sure that simple operation like max and min filters still give the same results. Parameters: Name Type Description Default grid_out List desired output grid of the compressed data, required Returns: Type Description ndarray Smoothed array Source code in pyrho/core/pgrid.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 def lossy_smooth_compression ( self , grid_out : List , smear_std : float = 0.2 ) -> np . ndarray : \"\"\" Perform Fourier interpolation then Gaussian smoothing. the smoothing makes sure that simple operation like max and min filters still give the same results. Args: grid_out: desired output grid of the compressed data, Returns: Smoothed array \"\"\" arr_interp = np . absolute ( interpolate_fourier ( self . grid_data , grid_out )) if smear_std > 0 : arr_interp , _ = self . gaussian_smear ( arr_in = arr_interp , sigma = smear_std ) return arr_interp","title":"lossy_smooth_compression()"},{"location":"reference/core/#pyrho.core.chargeDensity","text":"Main module.","title":"pyrho.core.chargeDensity"},{"location":"reference/core/#pyrho.core.chargeDensity.ChargeDensity","text":"","title":"ChargeDensity"},{"location":"reference/core/#pyrho.core.chargeDensity.ChargeDensity.lattice","text":"Override the lattice definition in PGrid","title":"lattice"},{"location":"reference/core/#pyrho.core.chargeDensity.ChargeDensity.rho","text":"Alias for the grid data, which should be the true charge density","title":"rho"},{"location":"reference/core/#pyrho.core.chargeDensity.ChargeDensity.__init__","text":"Class that contains functions to featurize volumetic data with periodic boundary conditions. Make sure the data being stored is grid-independent Parameters: Name Type Description Default grid_data ndarray Volumetric data to read in required structure Structure Atomic structure corresponding to the charge density required normalization str the normalization scheme: - 'vasp' sum of the data / number of grid points == number of electrons 'vasp' Source code in pyrho/core/chargeDensity.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def __init__ ( self , grid_data : np . ndarray , structure : Structure , normalization : str = \"vasp\" , ): \"\"\" Class that contains functions to featurize volumetic data with periodic boundary conditions. Make sure the data being stored is grid-independent Args: grid_data: Volumetric data to read in structure: Atomic structure corresponding to the charge density normalization: the normalization scheme: - 'vasp' sum of the data / number of grid points == number of electrons \"\"\" self . structure = structure . copy () self . normalization = normalization if normalization [ 0 ] . lower () == \"n\" : \"\"\" No rescaling \"\"\" scaled_data = grid_data elif normalization [ 0 ] . lower () == \"v\" : \"\"\" the standard charge density from VASP is given as (rho*V) such that: sum(rho)/NGRID = NELECT/UC_vol so the real rho is: rho = (rho*UC_vol)*NGRID/UC_vol/UC_vol where the second V account for the different number of electrons in different cells \"\"\" scaled_data = grid_data / self . structure . volume else : raise NotImplementedError ( \"Not a valid normalization scheme\" ) super () . __init__ ( grid_data = scaled_data , lattice = None )","title":"__init__()"},{"location":"reference/core/#pyrho.core.chargeDensity.ChargeDensity.get_reshaped_cell","text":"Motify the structure and data and return a new object containing the reshaped data Parameters: Name Type Description Default sc_mat Matrix to create the new cell required frac_shift translation to be applied on the cell after the matrix required new_grid density of the new grid, can also just take the desired 1000000000 Source code in pyrho/core/chargeDensity.py 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 def get_reshaped_cell ( self , sc_mat , frac_shift , new_grid = int ( 1e9 )): \"\"\" Motify the structure and data and return a new object containing the reshaped data Args: sc_mat: Matrix to create the new cell frac_shift: translation to be applied on the cell after the matrix transformation new_grid: density of the new grid, can also just take the desired dimension as a list. Returns: \"\"\" new_structure = self . structure * sc_mat new_structure . translate_sites ( list ( range ( len ( new_structure ))), - np . array ( frac_shift ) ) # determine the output grid lengths = new_structure . lattice . abc if isinstance ( new_grid , int ): ngrid = new_grid / new_structure . volume mult = ( np . prod ( lengths ) / ngrid ) ** ( 1 / 3 ) grid_out = [ int ( math . floor ( max ( l / mult , 1 ))) for l in lengths ] else : grid_out = new_grid new_rho = self . get_transformed_data ( sc_mat , frac_shift , grid_out = grid_out ) return self . from_rho ( new_rho , new_structure , self . normalization )","title":"get_reshaped_cell()"},{"location":"reference/core/#pyrho.core.chargeDensity.ChargeDensity.reorient_axis","text":"Change the orgientation of the lattice vector so that: a points along the x-axis, b is in the xy-plane, c is in the positive-z halve of space Source code in pyrho/core/chargeDensity.py 102 103 104 105 106 107 108 109 def reorient_axis ( self ) -> None : \"\"\" Change the orgientation of the lattice vector so that: a points along the x-axis, b is in the xy-plane, c is in the positive-z halve of space \"\"\" self . structure . lattice = Lattice . from_parameters ( * self . structure . lattice . abc , * self . structure . lattice . angles , vesta = True )","title":"reorient_axis()"},{"location":"reference/vis/","text":"\u00b6 get_plotly_scatter_plot_3d ( data_in , lat_mat , factor = 5 , logcolor = False , mask = None , opacity = 0.25 , marker_size = 5 ) \u00b6 Returns a plotly fig object for plotting. Parameters: Name Type Description Default data_in ndarray Structured grid data to be plotted required lat_mat ndarray Lattice vectors of the cell required factor int reduction factor of the grid points for plotting, only show [::factor] in each direction 5 logcolor bool If True, assign the color in log scale False mask ndarray Filter the points to plot None opacity float opacity of each point being plotted 0.25 marker_size int size of the markers in the 3D scatter plot 5 Returns: Type Description Figure plotly Figure object Source code in pyrho/vis/plotly.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def get_plotly_scatter_plot_3d ( data_in : np . ndarray , lat_mat : np . ndarray , factor : int = 5 , logcolor : bool = False , mask : np . ndarray = None , opacity : float = 0.25 , marker_size : int = 5 , ) -> go . Figure : \"\"\" Returns a plotly fig object for plotting. Args: data_in: Structured grid data to be plotted lat_mat: Lattice vectors of the cell factor: reduction factor of the grid points for plotting, only show [::factor] in each direction logcolor: If True, assign the color in log scale mask: Filter the points to plot opacity: opacity of each point being plotted marker_size: size of the markers in the 3D scatter plot Returns: plotly Figure object \"\"\" ss = slice ( 0 , None , factor ) trimmed_data = np . real ( data_in ) . copy () trimmed_data = trimmed_data [ ss , ss , ss ] if mask is not None : flat_mask = mask [ ss , ss , ss ] . flatten () else : flat_mask = np . ones_like ( trimmed_data , dtype = bool ) . flatten () av = np . linspace ( 0 , 1 , trimmed_data . shape [ 0 ], endpoint = False ) bv = np . linspace ( 0 , 1 , trimmed_data . shape [ 1 ], endpoint = False ) cv = np . linspace ( 0 , 1 , trimmed_data . shape [ 2 ], endpoint = False ) AA , BB , CC = np . meshgrid ( av , bv , cv , indexing = \"ij\" ) # indexing to match the labeled array res = np . dot ( lat_mat . T , [ AA . flatten (), BB . flatten (), CC . flatten ()]) if logcolor : cc = np . log ( trimmed_data . flatten ()) else : cc = trimmed_data . flatten () xx = res [ 0 , flat_mask ] yy = res [ 1 , flat_mask ] zz = res [ 2 , flat_mask ] cc = cc [ flat_mask ] # df = pandas.DataFrame({'x':xx, 'y':yy, 'z':zz, 'cc': cc}) # fig = px.scatter_3d(df, x='x', y='y', z='z', color='cc', opacity=opacity, size_max=2) fig = go . Figure ( data = [ go . Scatter3d ( x = xx , y = yy , z = zz , mode = \"markers\" , marker = dict ( size = marker_size , color = cc , # set color to an array/list of desired values colorscale = \"Viridis\" , # choose a colorscale opacity = opacity , ), ) ] ) # fig.update_layout(margin=dict(l=0, r=0, b=0, t=0)) fig . update_layout ( width = 700 , margin = { \"r\" : 10 , \"l\" : 10 , \"b\" : 10 , \"t\" : 10 }) # fix the ratio in the top left subplot to be a cube fig . update_layout ( scene_aspectmode = \"data\" ) return fig","title":"vis"},{"location":"reference/vis/#pyrho.vis.plotly","text":"","title":"pyrho.vis.plotly"},{"location":"reference/vis/#pyrho.vis.plotly.get_plotly_scatter_plot_3d","text":"Returns a plotly fig object for plotting. Parameters: Name Type Description Default data_in ndarray Structured grid data to be plotted required lat_mat ndarray Lattice vectors of the cell required factor int reduction factor of the grid points for plotting, only show [::factor] in each direction 5 logcolor bool If True, assign the color in log scale False mask ndarray Filter the points to plot None opacity float opacity of each point being plotted 0.25 marker_size int size of the markers in the 3D scatter plot 5 Returns: Type Description Figure plotly Figure object Source code in pyrho/vis/plotly.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def get_plotly_scatter_plot_3d ( data_in : np . ndarray , lat_mat : np . ndarray , factor : int = 5 , logcolor : bool = False , mask : np . ndarray = None , opacity : float = 0.25 , marker_size : int = 5 , ) -> go . Figure : \"\"\" Returns a plotly fig object for plotting. Args: data_in: Structured grid data to be plotted lat_mat: Lattice vectors of the cell factor: reduction factor of the grid points for plotting, only show [::factor] in each direction logcolor: If True, assign the color in log scale mask: Filter the points to plot opacity: opacity of each point being plotted marker_size: size of the markers in the 3D scatter plot Returns: plotly Figure object \"\"\" ss = slice ( 0 , None , factor ) trimmed_data = np . real ( data_in ) . copy () trimmed_data = trimmed_data [ ss , ss , ss ] if mask is not None : flat_mask = mask [ ss , ss , ss ] . flatten () else : flat_mask = np . ones_like ( trimmed_data , dtype = bool ) . flatten () av = np . linspace ( 0 , 1 , trimmed_data . shape [ 0 ], endpoint = False ) bv = np . linspace ( 0 , 1 , trimmed_data . shape [ 1 ], endpoint = False ) cv = np . linspace ( 0 , 1 , trimmed_data . shape [ 2 ], endpoint = False ) AA , BB , CC = np . meshgrid ( av , bv , cv , indexing = \"ij\" ) # indexing to match the labeled array res = np . dot ( lat_mat . T , [ AA . flatten (), BB . flatten (), CC . flatten ()]) if logcolor : cc = np . log ( trimmed_data . flatten ()) else : cc = trimmed_data . flatten () xx = res [ 0 , flat_mask ] yy = res [ 1 , flat_mask ] zz = res [ 2 , flat_mask ] cc = cc [ flat_mask ] # df = pandas.DataFrame({'x':xx, 'y':yy, 'z':zz, 'cc': cc}) # fig = px.scatter_3d(df, x='x', y='y', z='z', color='cc', opacity=opacity, size_max=2) fig = go . Figure ( data = [ go . Scatter3d ( x = xx , y = yy , z = zz , mode = \"markers\" , marker = dict ( size = marker_size , color = cc , # set color to an array/list of desired values colorscale = \"Viridis\" , # choose a colorscale opacity = opacity , ), ) ] ) # fig.update_layout(margin=dict(l=0, r=0, b=0, t=0)) fig . update_layout ( width = 700 , margin = { \"r\" : 10 , \"l\" : 10 , \"b\" : 10 , \"t\" : 10 }) # fix the ratio in the top left subplot to be a cube fig . update_layout ( scene_aspectmode = \"data\" ) return fig","title":"get_plotly_scatter_plot_3d()"}]}